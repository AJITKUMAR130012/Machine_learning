# -*- coding: utf-8 -*-
"""Batch Gradient (Linear regression).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vCnfYRLYBlM7gXrGh8t1hhI3VYzmYRgS
"""

import numpy as np
import pandas as pd
from sklearn.datasets import load_diabetes

X,y=load_diabetes(return_X_y=True)

X.shape, y.shape

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(X,y,random_state=2)

x_train.shape,y_train.shape,x_test.shape,y_test.shape

from sklearn.linear_model import LinearRegression

l=LinearRegression()

l.fit(x_train,y_train)

l.score(x_test,y_test)

l.intercept_

l.coef_

class GradientDecent:
  def __init__(self,lr,epoch):
    self.lr=lr
    self.epoch=epoch
    self.intercept=0
    self.coeff=np.zeros(X.shape[1])
  def fit(self,x_train,y_train):
    for i in range(1,self.epoch,1):

      y_hat=np.dot(x_train,self.coeff)+ self.intercept
      intercept_der=-2*np.mean(y_train-y_hat)
      self.intercept=self.intercept-(self.lr*intercept_der)

      cf_der=-2*np.dot((y_train-y_hat),x_train)/x_train.shape[0]
     
      self.coeff=self.coeff-self.lr*(cf_der)

    print(self.intercept)
    print(self.coeff)
  def predict(self,x_train):
    return np.dot(x_train,self.coeff)+self.intercept

g=GradientDecent(0.01,1000)

g.fit(x_train,y_train)

g.predict(x_train)

l.predict(x_train)

