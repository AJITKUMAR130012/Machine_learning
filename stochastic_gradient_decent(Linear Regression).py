# -*- coding: utf-8 -*-
"""Stochastic Gradient Decent.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AHO9snN6HQS-NnTh5QmUBUcE1RTZBzyb
"""

import numpy as np
import pandas as pd
from sklearn.datasets import make_regression
import random
from sklearn.metrics import r2_score

X,y=make_regression(n_samples=100,n_features=3,n_informative=3,n_targets=1,noise=40,random_state=10)

y.shape

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y)

X_train.shape, X_test.shape

from sklearn.linear_model import LinearRegression

l=LinearRegression()

l.fit(X_train,y_train)

l.score(X_test,y_test)

l.intercept_

l.coef_

y_pred1=l.predict(X_test)

r2_score(y_test,y_pred1)

X_train.shape

class GradientDecent:
    def __init__(self,lr,epoch):
        self.lr=lr
        self.epoch=epoch
        self.intercept=0
        self.coff=np.ones(X_train.shape[1])
    def fit(self,X_train,y_train):

        for j in range(0,self.epoch):
            
            for i in range(X_train.shape[0]):

                idx=np.random.randint(0,X_train.shape[0]) 

                y_hat=np.dot(X_train[idx],self.coff)+self.intercept

                int_der=-2*(y_train[idx]-y_hat)

                self.intercept=self.intercept-self.lr*int_der

                coef_der=-2*np.dot((y_train[idx]-y_hat),X_train[idx])

                self.coff=self.coff-self.lr*coef_der

        print(self.intercept,self.coff)

    def predict(self,X_test):
        return np.dot(X_test,self.coff)+self.intercept

f=GradientDecent(0.01,10)

f.fit(X_train,y_train)

y_pred=f.predict(X_test)

r2_score(y_test,y_pred)

